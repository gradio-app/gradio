{"cells": [{"cell_type": "markdown", "id": "302934307671667531413257853548643485645", "metadata": {}, "source": ["# Gradio Demo: main_note"]}, {"cell_type": "code", "execution_count": null, "id": "272996653310673477252411125948039410165", "metadata": {}, "outputs": [], "source": ["!pip install -q gradio scipy numpy matplotlib"]}, {"cell_type": "code", "execution_count": null, "id": "288918539441861185822528903084949547379", "metadata": {}, "outputs": [], "source": ["from math import log2, pow\n", "\n", "import numpy as np\n", "from scipy.fftpack import fft\n", "\n", "import gradio as gr\n", "from gradio.media import get_audio\n", "\n", "A4 = 440\n", "C0 = A4 * pow(2, -4.75)\n", "name = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n", "\n", "def get_pitch(freq):\n", "    h = round(12 * log2(freq / C0))\n", "    n = h % 12\n", "    return name[n]\n", "\n", "def main_note(audio):\n", "    rate, y = audio\n", "    if len(y.shape) == 2:\n", "        y = y.T[0]\n", "    N = len(y)\n", "    T = 1.0 / rate\n", "    yf = fft(y)\n", "    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n", "    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n", "\n", "    volume_per_pitch = {}\n", "    total_volume = np.sum(yf2)\n", "    for freq, volume in zip(xf, yf2):\n", "        if freq == 0:\n", "            continue\n", "        pitch = get_pitch(freq)\n", "        if pitch not in volume_per_pitch:\n", "            volume_per_pitch[pitch] = 0\n", "        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n", "    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n", "    return volume_per_pitch\n", "\n", "demo = gr.Interface(\n", "    main_note,\n", "    gr.Audio(sources=[\"microphone\"]),\n", "    gr.Label(num_top_classes=4),\n", "    examples=[\n", "        [get_audio(\"recording1.wav\")],\n", "        [get_audio(\"cantina.wav\")],\n", "    ],\n", ")\n", "\n", "if __name__ == \"__main__\":\n", "    demo.launch()\n"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}