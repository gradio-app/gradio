{"cells": [{"cell_type": "markdown", "id": "302934307671667531413257853548643485645", "metadata": {}, "source": ["# Gradio Demo: llm_llamaindex"]}, {"cell_type": "code", "execution_count": null, "id": "272996653310673477252411125948039410165", "metadata": {}, "outputs": [], "source": ["!pip install -q gradio openai llama-index "]}, {"cell_type": "code", "execution_count": null, "id": "288918539441861185822528903084949547379", "metadata": {}, "outputs": [], "source": ["# Downloading files from the demo repo\n", "import os\n", "!wget -q https://github.com/gradio-app/gradio/raw/main/demo/llm_llamaindex/paul_graham.txt"]}, {"cell_type": "code", "execution_count": null, "id": "44380577570523278879349135829904343037", "metadata": {}, "outputs": [], "source": ["# This is a simple RAG chatbot built on top of Llama Index and Gradio. It allows you to upload any text or PDF files and ask questions about them!\n", "# Before running this, make sure you have exported your OpenAI API key as an environment variable:\n", "# export OPENAI_API_KEY=\"your-openai-api-key\"\n", "\n", "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "import gradio as gr\n", "\n", "def answer(message, history):\n", "    files = []\n", "    for msg in history:\n", "        if msg['role'] == \"user\" and isinstance(msg['content'], tuple):\n", "            files.append(msg['content'][0])\n", "    for file in message[\"files\"]:\n", "        files.append(file)\n", "\n", "    documents = SimpleDirectoryReader(input_files=files).load_data()\n", "    index = VectorStoreIndex.from_documents(documents)\n", "    query_engine = index.as_query_engine()\n", "    return str(query_engine.query(message[\"text\"]))\n", "\n", "demo = gr.ChatInterface(\n", "    answer,\n", "    type=\"messages\",\n", "    title=\"Llama Index RAG Chatbot\",\n", "    description=\"Upload any text or pdf files and ask questions about them!\",\n", "    textbox=gr.MultimodalTextbox(file_types=[\".pdf\", \".txt\"]),\n", "    multimodal=True\n", ")\n", "\n", "if __name__ == \"__main__\":\n", "    demo.launch()\n"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}