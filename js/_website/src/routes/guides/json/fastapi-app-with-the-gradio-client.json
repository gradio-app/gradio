{"guide": {"name": "fastapi-app-with-the-gradio-client", "category": "client-libraries", "pretty_category": "Client Libraries", "guide_index": null, "absolute_index": 31, "pretty_name": "Fastapi App With The Gradio Client", "content": "# Building a FastAPI App with the Gradio Python Client\n\n\n\nIn this blog post, we will demonstrate how to use the `gradio_client` [Python library](getting-started-with-the-python-client/), which enables developers to make requests to a Gradio app programmatically, by creating an example FastAPI web app. The web app we will be building is called \"Acapellify,\" and it will allow users to upload video files as input and return a version of that video without instrumental music. It will also display a gallery of generated videos.\n\n\n**Prerequisites**\n\nBefore we begin, make sure you are running Python 3.9 or later, and have the following libraries installed:\n\n* `gradio_client`\n* `fastapi`\n* `uvicorn`\n\nYou can install these libraries from `pip`: \n\n```bash\n$ pip install gradio_client fastapi uvicorn\n```\n\nYou will also need to have ffmpeg installed. You can check to see if you already have ffmpeg by running in your terminal:\n\n```bash\n$ ffmpeg version\n```\n\nOtherwise, install ffmpeg [by following these instructions](https://www.hostinger.com/tutorials/how-to-install-ffmpeg).\n\n## Step 1: Write the Video Processing Function\n\nLet's start with what seems like the most complex bit -- using machine learning to remove the music from a video. \n\nLuckily for us, there's an existing Space we can use to make this process easier: [https://huggingface.co/spaces/abidlabs/music-separation](https://huggingface.co/spaces/abidlabs/music-separation). This Space takes an audio file and produces two separate audio files: one with the instrumental music and one with all other sounds in the original clip. Perfect to use with our client! \n\nOpen a new Python file, say `main.py`, and start by importing the `Client` class from `gradio_client` and connecting it to this Space:\n\n```py\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/music-separation\")\n\ndef acapellify(audio_path):\n    result = client.predict(audio_path, api_name=\"/predict\")\n    return result[0]\n```\n\nThat's all the code that's needed -- notice that the API endpoints returns two audio files (one without the music, and one with just the music) in a list, and so we just return the first element of the list. \n\n---\n\n**Note**: since this is a public Space, there might be other users using this Space as well, which might result in a slow experience. You can duplicate this Space with your own [Hugging Face token](https://huggingface.co/settings/tokens) and create a private Space that only you have will have access to and bypass the queue. To do that, simply replace the first two lines above with: \n\n```py\nfrom gradio_client import Client\n\nclient = Client.duplicate(\"abidlabs/music-separation\", hf_token=YOUR_HF_TOKEN)\n```\n\nEverything else remains the same!\n\n---\n\nNow, of course, we are working with video files, so we first need to extract the audio from the video files. For this, we will be using the `ffmpeg` library, which does a lot of heavy lifting when it comes to working with audio and video files. The most common way to use `ffmpeg` is through the command line, which we'll call via Python's `subprocess` module:\n\nOur video processing workflow will consist of three steps: \n\n1. First, we start by taking in a video filepath and extracting the audio using `ffmpeg`. \n2. Then, we pass in the audio file through the `acapellify()` function above.\n3. Finally, we combine the new audio with the original video to produce a final acapellified video. \n\nHere's the complete code in Python, which you can add to your `main.py` file:\n\n```python\nimport subprocess\n\ndef process_video(video_path):\n    old_audio = os.path.basename(video_path).split(\".\")[0] + \".m4a\"\n    subprocess.run(['ffmpeg', '-y', '-i', video_path, '-vn', '-acodec', 'copy', old_audio])\n    \n    new_audio = acapellify(old_audio)\n    \n    new_video = f\"acap_{video_path}\"\n    subprocess.call(['ffmpeg', '-y', '-i', video_path, '-i', new_audio, '-map', '0:v', '-map', '1:a', '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental', f\"static/{new_video}\"])\n    return new_video\n```\n\nYou can read up on [ffmpeg documentation](https://ffmpeg.org/ffmpeg.html) if you'd like to understand all of the command line parameters, as they are beyond the scope of this tutorial.\n\n## Step 2: Create a FastAPI app (Backend Routes)\n\nNext up, we'll create a simple FastAPI app. If you haven't used FastAPI before, check out [the great FastAPI docs](https://fastapi.tiangolo.com/). Otherwise, this basic template, which we add to `main.py`, will look pretty familiar:\n\n```python\nimport os\nfrom fastapi import FastAPI, File, UploadFile, Request\nfrom fastapi.responses import HTMLResponse, RedirectResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\n\napp = FastAPI()\nos.makedirs(\"static\", exist_ok=True)\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\nvideos = []\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def home(request: Request):\n    return templates.TemplateResponse(\n        \"home.html\", {\"request\": request, \"videos\": videos})\n\n@app.post(\"/uploadvideo/\")\nasync def upload_video(video: UploadFile = File(...)):\n    new_video = process_video(video.filename)\n    videos.append(new_video)\n    return RedirectResponse(url='/', status_code=303)\n```\n\nIn this example, the FastAPI app has two routes: `/` and `/uploadvideo/`.\n\nThe `/` route returns an HTML template that displays a gallery of all uploaded videos. \n\nThe `/uploadvideo/` route accepts a `POST` request with an `UploadFile` object, which represents the uploaded video file. The video file is \"acapellified\" via the `process_video()` method, and the output video is stored in a list which stores all of the uploaded videos in memory.\n\nNote that this is a very basic example and if this were a production app, you will need to add more logic to handle file storage, user authentication, and security considerations. \n\n## Step 3: Create a FastAPI app (Frontend Template)\n\nFinally, we create the frontend of our web application. First, we create a folder called `templates` in the same directory as `main.py`. We then create a template, `home.html` inside the `templates` folder. Here is the resulting file structure:\n\n```csv\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 templates\n\u2502   \u2514\u2500\u2500 home.html\n```\n\nWrite the following as the contents of `home.html`:\n\n```html\n&lt;!DOCTYPE html>\n&lt;html>\n  &lt;head>\n    &lt;title>Video Gallery&lt;/title>\n    &lt;style>\n      body {\n        font-family: sans-serif;\n        margin: 0;\n        padding: 0;\n        background-color: #f5f5f5;\n      }\n      h1 {\n        text-align: center;\n        margin-top: 30px;\n        margin-bottom: 20px;\n      }\n      .gallery {\n        display: flex;\n        flex-wrap: wrap;\n        justify-content: center;\n        gap: 20px;\n        padding: 20px;\n      }\n      .video {\n        border: 2px solid #ccc;\n        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.2);\n        border-radius: 5px;\n        overflow: hidden;\n        width: 300px;\n        margin-bottom: 20px;\n      }\n      .video video {\n        width: 100%;\n        height: 200px;\n      }\n      .video p {\n        text-align: center;\n        margin: 10px 0;\n      }\n      form {\n        margin-top: 20px;\n        text-align: center;\n      }\n      input[type=\"file\"] {\n        display: none;\n      }\n      .upload-btn {\n        display: inline-block;\n        background-color: #3498db;\n        color: #fff;\n        padding: 10px 20px;\n        font-size: 16px;\n        border: none;\n        border-radius: 5px;\n        cursor: pointer;\n      }\n      .upload-btn:hover {\n        background-color: #2980b9;\n      }\n      .file-name {\n        margin-left: 10px;\n      }\n    &lt;/style>\n  &lt;/head>\n  &lt;body>\n    &lt;h1>Video Gallery&lt;/h1>\n    {% if videos %}\n      &lt;div class=\"gallery\">\n        {% for video in videos %}\n          &lt;div class=\"video\">\n            &lt;video controls>\n              &lt;source src=\"{{ url_for('static', path=video) }}\" type=\"video/mp4\">\n              Your browser does not support the video tag.\n            &lt;/video>\n            &lt;p>{{ video }}&lt;/p>\n          &lt;/div>\n        {% endfor %}\n      &lt;/div>\n    {% else %}\n      &lt;p>No videos uploaded yet.&lt;/p>\n    {% endif %}\n    &lt;form action=\"/uploadvideo/\" method=\"post\" enctype=\"multipart/form-data\">\n      &lt;label for=\"video-upload\" class=\"upload-btn\">Choose video file&lt;/label>\n      &lt;input type=\"file\" name=\"video\" id=\"video-upload\">\n      &lt;span class=\"file-name\">&lt;/span>\n      &lt;button type=\"submit\" class=\"upload-btn\">Upload&lt;/button>\n    &lt;/form>\n    &lt;script>\n      // Display selected file name in the form\n      const fileUpload = document.getElementById(\"video-upload\");\n      const fileName = document.querySelector(\".file-name\");\n\n      fileUpload.addEventListener(\"change\", (e) => {\n        fileName.textContent = e.target.files[0].name;\n      });\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n```\n\n## Step 4: Run your FastAPI app\n\nFinally, we are ready to run our FastAPI app, powered by the Gradio Python Client!\n\nOpen up a terminal and navigate to the directory containing `main.py`. Then run the following command in the terminal:\n\n```bash\n$ uvicorn main:app\n```\n\nYou should see an output that looks like this:\n\n```csv\nLoaded as API: https://abidlabs-music-separation.hf.space \u2714\nINFO:     Started server process [1360]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n```\n\nAnd that's it! Start uploading videos and you'll get some \"acapellified\" videos in response (might take seconds to minutes to process depending on the length of your videos). Here's how the UI looks after uploading two videos:\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/acapellify.png)\n\n If you'd like to learn more about how to use the Gradio Python Client in your projects, [read the dedicated Guide](/guides/getting-started-with-the-python-client/).\n\n", "html": "<h1 id=\"building-a-fastapi-app-with-the-gradio-python-client\">Building a FastAPI App with the Gradio Python Client</h1>\n\n<p>In this blog post, we will demonstrate how to use the <code>gradio_client</code> <a rel=\"noopener\" target=\"_blank\" href=\"getting-started-with-the-python-client/\">Python library</a>, which enables developers to make requests to a Gradio app programmatically, by creating an example FastAPI web app. The web app we will be building is called \"Acapellify,\" and it will allow users to upload video files as input and return a version of that video without instrumental music. It will also display a gallery of generated videos.</p>\n\n<p><strong>Prerequisites</strong></p>\n\n<p>Before we begin, make sure you are running Python 3.9 or later, and have the following libraries installed:</p>\n\n<ul>\n<li><code>gradio_client</code></li>\n<li><code>fastapi</code></li>\n<li><code>uvicorn</code></li>\n</ul>\n\n<p>You can install these libraries from <code>pip</code>: </p>\n\n<div class='codeblock'><pre><code class='lang-bash'>$ pip install gradio_client fastapi uvicorn\n</code></pre></div>\n\n<p>You will also need to have ffmpeg installed. You can check to see if you already have ffmpeg by running in your terminal:</p>\n\n<div class='codeblock'><pre><code class='lang-bash'>$ ffmpeg version\n</code></pre></div>\n\n<p>Otherwise, install ffmpeg <a rel=\"noopener\" target=\"_blank\" href=\"https://www.hostinger.com/tutorials/how-to-install-ffmpeg\">by following these instructions</a>.</p>\n\n<h2 id=\"step-1-write-the-video-processing-function\">Step 1: Write the Video Processing Function</h2>\n\n<p>Let's start with what seems like the most complex bit -- using machine learning to remove the music from a video. </p>\n\n<p>Luckily for us, there's an existing Space we can use to make this process easier: <a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/spaces/abidlabs/music-separation\">https://huggingface.co/spaces/abidlabs/music-separation</a>. This Space takes an audio file and produces two separate audio files: one with the instrumental music and one with all other sounds in the original clip. Perfect to use with our client! </p>\n\n<p>Open a new Python file, say <code>main.py</code>, and start by importing the <code>Client</code> class from <code>gradio_client</code> and connecting it to this Space:</p>\n\n<div class='codeblock'><pre><code class='lang-py'>from gradio_client import Client\n\nclient = Client(\"abidlabs/music-separation\")\n\ndef acapellify(audio_path):\n    result = client.predict(audio_path, api_name=\"/predict\")\n    return result[0]\n</code></pre></div>\n\n<p>That's all the code that's needed -- notice that the API endpoints returns two audio files (one without the music, and one with just the music) in a list, and so we just return the first element of the list. </p>\n\n<hr />\n\n<p><strong>Note</strong>: since this is a public Space, there might be other users using this Space as well, which might result in a slow experience. You can duplicate this Space with your own <a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/settings/tokens\">Hugging Face token</a> and create a private Space that only you have will have access to and bypass the queue. To do that, simply replace the first two lines above with: </p>\n\n<div class='codeblock'><pre><code class='lang-py'>from gradio_client import Client\n\nclient = Client.duplicate(\"abidlabs/music-separation\", hf_token=YOUR_HF_TOKEN)\n</code></pre></div>\n\n<p>Everything else remains the same!</p>\n\n<hr />\n\n<p>Now, of course, we are working with video files, so we first need to extract the audio from the video files. For this, we will be using the <code>ffmpeg</code> library, which does a lot of heavy lifting when it comes to working with audio and video files. The most common way to use <code>ffmpeg</code> is through the command line, which we'll call via Python's <code>subprocess</code> module:</p>\n\n<p>Our video processing workflow will consist of three steps: </p>\n\n<ol>\n<li>First, we start by taking in a video filepath and extracting the audio using <code>ffmpeg</code>. </li>\n<li>Then, we pass in the audio file through the <code>acapellify()</code> function above.</li>\n<li>Finally, we combine the new audio with the original video to produce a final acapellified video. </li>\n</ol>\n\n<p>Here's the complete code in Python, which you can add to your <code>main.py</code> file:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import subprocess\n\ndef process_video(video_path):\n    old_audio = os.path.basename(video_path).split(\".\")[0] + \".m4a\"\n    subprocess.run(['ffmpeg', '-y', '-i', video_path, '-vn', '-acodec', 'copy', old_audio])\n\n    new_audio = acapellify(old_audio)\n\n    new_video = f\"acap_{video_path}\"\n    subprocess.call(['ffmpeg', '-y', '-i', video_path, '-i', new_audio, '-map', '0:v', '-map', '1:a', '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental', f\"static/{new_video}\"])\n    return new_video\n</code></pre></div>\n\n<p>You can read up on <a rel=\"noopener\" target=\"_blank\" href=\"https://ffmpeg.org/ffmpeg.html\">ffmpeg documentation</a> if you'd like to understand all of the command line parameters, as they are beyond the scope of this tutorial.</p>\n\n<h2 id=\"step-2-create-a-fastapi-app-backend-routes\">Step 2: Create a FastAPI app (Backend Routes)</h2>\n\n<p>Next up, we'll create a simple FastAPI app. If you haven't used FastAPI before, check out <a rel=\"noopener\" target=\"_blank\" href=\"https://fastapi.tiangolo.com/\">the great FastAPI docs</a>. Otherwise, this basic template, which we add to <code>main.py</code>, will look pretty familiar:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import os\nfrom fastapi import FastAPI, File, UploadFile, Request\nfrom fastapi.responses import HTMLResponse, RedirectResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\n\napp = FastAPI()\nos.makedirs(\"static\", exist_ok=True)\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\nvideos = []\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def home(request: Request):\n    return templates.TemplateResponse(\n        \"home.html\", {\"request\": request, \"videos\": videos})\n\n@app.post(\"/uploadvideo/\")\nasync def upload_video(video: UploadFile = File(...)):\n    new_video = process_video(video.filename)\n    videos.append(new_video)\n    return RedirectResponse(url='/', status_code=303)\n</code></pre></div>\n\n<p>In this example, the FastAPI app has two routes: <code>/</code> and <code>/uploadvideo/</code>.</p>\n\n<p>The <code>/</code> route returns an HTML template that displays a gallery of all uploaded videos. </p>\n\n<p>The <code>/uploadvideo/</code> route accepts a <code>POST</code> request with an <code>UploadFile</code> object, which represents the uploaded video file. The video file is \"acapellified\" via the <code>process_video()</code> method, and the output video is stored in a list which stores all of the uploaded videos in memory.</p>\n\n<p>Note that this is a very basic example and if this were a production app, you will need to add more logic to handle file storage, user authentication, and security considerations. </p>\n\n<h2 id=\"step-3-create-a-fastapi-app-frontend-template\">Step 3: Create a FastAPI app (Frontend Template)</h2>\n\n<p>Finally, we create the frontend of our web application. First, we create a folder called <code>templates</code> in the same directory as <code>main.py</code>. We then create a template, <code>home.html</code> inside the <code>templates</code> folder. Here is the resulting file structure:</p>\n\n<div class='codeblock'><pre><code class='lang-csv'>\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 templates\n\u2502   \u2514\u2500\u2500 home.html\n</code></pre></div>\n\n<p>Write the following as the contents of <code>home.html</code>:</p>\n\n<div class='codeblock'><pre><code class='lang-html'>&lt;!DOCTYPE html>\n&lt;html>\n  &lt;head>\n    &lt;title>Video Gallery&lt;/title>\n    &lt;style>\n      body {\n        font-family: sans-serif;\n        margin: 0;\n        padding: 0;\n        background-color: #f5f5f5;\n      }\n      h1 {\n        text-align: center;\n        margin-top: 30px;\n        margin-bottom: 20px;\n      }\n      .gallery {\n        display: flex;\n        flex-wrap: wrap;\n        justify-content: center;\n        gap: 20px;\n        padding: 20px;\n      }\n      .video {\n        border: 2px solid #ccc;\n        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.2);\n        border-radius: 5px;\n        overflow: hidden;\n        width: 300px;\n        margin-bottom: 20px;\n      }\n      .video video {\n        width: 100%;\n        height: 200px;\n      }\n      .video p {\n        text-align: center;\n        margin: 10px 0;\n      }\n      form {\n        margin-top: 20px;\n        text-align: center;\n      }\n      input[type=\"file\"] {\n        display: none;\n      }\n      .upload-btn {\n        display: inline-block;\n        background-color: #3498db;\n        color: #fff;\n        padding: 10px 20px;\n        font-size: 16px;\n        border: none;\n        border-radius: 5px;\n        cursor: pointer;\n      }\n      .upload-btn:hover {\n        background-color: #2980b9;\n      }\n      .file-name {\n        margin-left: 10px;\n      }\n    &lt;/style>\n  &lt;/head>\n  &lt;body>\n    &lt;h1>Video Gallery&lt;/h1>\n    {% if videos %}\n      &lt;div class=\"gallery\">\n        {% for video in videos %}\n          &lt;div class=\"video\">\n            &lt;video controls>\n              &lt;source src=\"{{ url_for('static', path=video) }}\" type=\"video/mp4\">\n              Your browser does not support the video tag.\n            &lt;/video>\n            &lt;p>{{ video }}&lt;/p>\n          &lt;/div>\n        {% endfor %}\n      &lt;/div>\n    {% else %}\n      &lt;p>No videos uploaded yet.&lt;/p>\n    {% endif %}\n    &lt;form action=\"/uploadvideo/\" method=\"post\" enctype=\"multipart/form-data\">\n      &lt;label for=\"video-upload\" class=\"upload-btn\">Choose video file&lt;/label>\n      &lt;input type=\"file\" name=\"video\" id=\"video-upload\">\n      &lt;span class=\"file-name\">&lt;/span>\n      &lt;button type=\"submit\" class=\"upload-btn\">Upload&lt;/button>\n    &lt;/form>\n    &lt;script>\n      // Display selected file name in the form\n      const fileUpload = document.getElementById(\"video-upload\");\n      const fileName = document.querySelector(\".file-name\");\n\n      fileUpload.addEventListener(\"change\", (e) => {\n        fileName.textContent = e.target.files[0].name;\n      });\n    &lt;/script>\n  &lt;/body>\n&lt;/html>\n</code></pre></div>\n\n<h2 id=\"step-4-run-your-fastapi-app\">Step 4: Run your FastAPI app</h2>\n\n<p>Finally, we are ready to run our FastAPI app, powered by the Gradio Python Client!</p>\n\n<p>Open up a terminal and navigate to the directory containing <code>main.py</code>. Then run the following command in the terminal:</p>\n\n<div class='codeblock'><pre><code class='lang-bash'>$ uvicorn main:app\n</code></pre></div>\n\n<p>You should see an output that looks like this:</p>\n\n<div class='codeblock'><pre><code class='lang-csv'>Loaded as API: https://abidlabs-music-separation.hf.space \u2714\nINFO:     Started server process [1360]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n</code></pre></div>\n\n<p>And that's it! Start uploading videos and you'll get some \"acapellified\" videos in response (might take seconds to minutes to process depending on the length of your videos). Here's how the UI looks after uploading two videos:</p>\n\n<p><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/acapellify.png\" alt=\"\" /></p>\n\n<p>If you'd like to learn more about how to use the Gradio Python Client in your projects, <a rel=\"noopener\" target=\"_blank\" href=\"/guides/getting-started-with-the-python-client/\">read the dedicated Guide</a>.</p>\n", "tags": ["CLIENT", "API", "WEB APP"], "spaces": [], "url": "/guides/fastapi-app-with-the-gradio-client/", "contributor": null}}